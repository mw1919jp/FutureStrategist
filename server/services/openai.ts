import OpenAI from "openai";
import { logApiRequest, logApiResponse } from "../utils/logger";
import type { YearResult } from "@shared/schema";

// the newest OpenAI model is "gpt-5" which was released August 7, 2025. do not change this unless explicitly requested by the user
const openai = new OpenAI({ 
  apiKey: process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY_ENV_VAR || "default_key" 
});

// Ultra-fast OpenAI client specifically for expert prediction with no retries and 1.8s timeout
const fastOpenai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY_ENV_VAR || "default_key",
  maxRetries: 0,
  timeout: 1800, // 1.8 second timeout to guarantee <2s total response
});

// In-memory cache for expert predictions with TTL
interface CacheEntry {
  data: ExpertPrediction;
  timestamp: number;
  ttl: number;
}

// Circuit breaker state management
interface CircuitBreakerState {
  failureCount: number;
  lastFailureTime: number;
  isOpen: boolean;
}

const predictionCache = new Map<string, CacheEntry>();
const inflightRequests = new Map<string, Promise<ExpertPrediction>>();
const circuitBreaker = new Map<string, CircuitBreakerState>();

// Cache TTL: 15 minutes
const CACHE_TTL = 15 * 60 * 1000;
// Circuit breaker timeout: 10 seconds
const CIRCUIT_BREAKER_TIMEOUT = 10 * 1000;
// Hard deadline for total response: 2 seconds
const HARD_DEADLINE = 2000;

export interface ExpertAnalysis {
  expert: string;
  content: string;
  recommendations: string[];
}

export interface PhaseResult {
  phase: number;
  title: string;
  content: string;
  analyses?: ExpertAnalysis[];
  recommendations?: string[];
}

export interface ScenarioAnalysisResult {
  phases: PhaseResult[];
  finalRecommendations: string[];
  markdownReport: string;
}

export interface ExpertPrediction {
  role: string;
  specialization: string;
  expertiseLevel: string;
  subSpecializations: string[];
  informationSources: string[];
  researchFocus: string;
}

// Template-based fallback responses for common expert types
const expertFallbackTemplates: Record<string, ExpertPrediction> = {
  "AIç ”ç©¶è€…": {
    role: "äººå·¥çŸ¥èƒ½ç ”ç©¶ãƒ»é–‹ç™ºå°‚é–€å®¶",
    specialization: "æ©Ÿæ¢°å­¦ç¿’ãƒ»æ·±å±¤å­¦ç¿’",
    expertiseLevel: "expert",
    subSpecializations: ["è‡ªç„¶è¨€èªå‡¦ç†", "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³", "å¼·åŒ–å­¦ç¿’"],
    informationSources: ["å­¦è¡“è«–æ–‡", "æŠ€è¡“ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹"],
    researchFocus: "AIæŠ€è¡“ã®å®Ÿç”¨åŒ–ã¨å€«ç†çš„èª²é¡Œ"
  },
  "çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ": {
    role: "ä¼æ¥­æˆ¦ç•¥ãƒ»çµŒå–¶æ”¹å–„å°‚é–€å®¶",
    specialization: "çµŒå–¶æˆ¦ç•¥ãƒ»çµ„ç¹”å¤‰é©",
    expertiseLevel: "senior",
    subSpecializations: ["ãƒ‡ã‚¸ã‚¿ãƒ«å¤‰é©", "äº‹æ¥­å†ç·¨", "çµ„ç¹”é–‹ç™º"],
    informationSources: ["å¸‚å ´èª¿æŸ»", "æ¥­ç•Œãƒ¬ãƒãƒ¼ãƒˆ"],
    researchFocus: "æŒç¶šçš„ç«¶äº‰å„ªä½ã®æ§‹ç¯‰"
  },
  "çµŒæ¸ˆå­¦è€…": {
    role: "çµŒæ¸ˆåˆ†æãƒ»æ”¿ç­–ç ”ç©¶å°‚é–€å®¶",
    specialization: "ãƒã‚¯ãƒ­çµŒæ¸ˆãƒ»é‡‘èæ”¿ç­–",
    expertiseLevel: "expert",
    subSpecializations: ["é‡‘èå¸‚å ´", "å›½éš›çµŒæ¸ˆ", "åŠ´åƒçµŒæ¸ˆ"],
    informationSources: ["çµ±è¨ˆãƒ‡ãƒ¼ã‚¿", "æ”¿åºœå ±å‘Šæ›¸"],
    researchFocus: "çµŒæ¸ˆå‹•å‘ã¨æ”¿ç­–åŠ¹æœã®åˆ†æ"
  },
  "æŠ€è¡“è€…": {
    role: "æŠ€è¡“é–‹ç™ºãƒ»ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå°‚é–€å®¶",
    specialization: "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒ»ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º",
    expertiseLevel: "expert",
    subSpecializations: ["ã‚¯ãƒ©ã‚¦ãƒ‰æŠ€è¡“", "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£"],
    informationSources: ["æŠ€è¡“æ–‡æ›¸", "é–‹ç™ºã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£"],
    researchFocus: "æŠ€è¡“é©æ–°ã¨å®Ÿè£…åŠ¹ç‡ã®å‘ä¸Š"
  },
  "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°å°‚é–€å®¶": {
    role: "å¸‚å ´åˆ†æãƒ»é¡§å®¢æˆ¦ç•¥å°‚é–€å®¶",
    specialization: "ãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°",
    expertiseLevel: "expert",
    subSpecializations: ["ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢", "ãƒ‡ãƒ¼ã‚¿åˆ†æ", "ãƒ–ãƒ©ãƒ³ãƒ‰æˆ¦ç•¥"],
    informationSources: ["æ¶ˆè²»è€…èª¿æŸ»", "å¸‚å ´ãƒ‡ãƒ¼ã‚¿"],
    researchFocus: "é¡§å®¢ä½“é¨“ã®æœ€é©åŒ–ã¨åç›Šå‘ä¸Š"
  }
};

export class OpenAIService {
  // Cache management methods
  private getCachedPrediction(expertName: string): ExpertPrediction | null {
    const entry = predictionCache.get(expertName);
    if (!entry) return null;
    
    const now = Date.now();
    if (now - entry.timestamp > entry.ttl) {
      predictionCache.delete(expertName);
      return null;
    }
    
    console.log(`[ExpertPrediction] Cache hit for ${expertName}`);
    return entry.data;
  }

  private cachePrediction(expertName: string, prediction: ExpertPrediction): void {
    predictionCache.set(expertName, {
      data: prediction,
      timestamp: Date.now(),
      ttl: CACHE_TTL
    });
  }

  // Circuit breaker management
  private shouldBreakCircuit(expertName: string): boolean {
    const state = circuitBreaker.get(expertName);
    if (!state) return false;
    
    const now = Date.now();
    if (state.isOpen && (now - state.lastFailureTime) > CIRCUIT_BREAKER_TIMEOUT) {
      // Reset circuit breaker after timeout
      circuitBreaker.delete(expertName);
      console.log(`[ExpertPrediction] Circuit breaker reset for ${expertName}`);
      return false;
    }
    
    if (state.isOpen) {
      console.log(`[ExpertPrediction] Circuit breaker open for ${expertName}, using fallback`);
      return true;
    }
    
    return false;
  }

  private recordCircuitBreakerFailure(expertName: string, error: any): void {
    const now = Date.now();
    const state = circuitBreaker.get(expertName) || { failureCount: 0, lastFailureTime: 0, isOpen: false };
    
    // Check for known failure conditions
    const isKnownFailure = 
      error.code === 'insufficient_quota' ||
      error.status === 429 ||
      error.code === 'ETIMEDOUT' ||
      error.message?.includes('Request timed out') ||
      error.message?.includes('timeout');
    
    if (isKnownFailure) {
      state.failureCount += 1;
      state.lastFailureTime = now;
      state.isOpen = state.failureCount >= 2; // Open circuit after 2 failures
      
      circuitBreaker.set(expertName, state);
      console.log(`[ExpertPrediction] Circuit breaker failure recorded for ${expertName}. Count: ${state.failureCount}, Open: ${state.isOpen}`);
    }
  }

  private getFallbackPrediction(expertName: string): ExpertPrediction {
    // Check for exact matches first
    const exactMatch = expertFallbackTemplates[expertName];
    if (exactMatch) {
      return exactMatch;
    }

    // Check for partial matches in expert name
    for (const [templateKey, template] of Object.entries(expertFallbackTemplates)) {
      if (expertName.includes(templateKey) || templateKey.includes(expertName)) {
        return {
          ...template,
          role: `${expertName} - ${template.role}`
        };
      }
    }

    // Generic fallback
    return {
      role: `${expertName} - å°‚é–€åˆ†é‡ã®å°‚é–€å®¶`,
      specialization: "å°‚é–€åˆ†é‡",
      expertiseLevel: "expert",
      subSpecializations: ["å°‚é–€é ˜åŸŸ1", "å°‚é–€é ˜åŸŸ2", "å°‚é–€é ˜åŸŸ3"],
      informationSources: ["å°‚é–€æ–‡çŒ®", "æ¥­ç•Œæƒ…å ±"],
      researchFocus: "åˆ†é‡ã®ç™ºå±•ã¨å®Ÿç”¨åŒ–"
    };
  }

  async predictExpertInfo(expertName: string): Promise<ExpertPrediction> {
    const startTime = Date.now();
    
    console.log(`[ExpertPrediction] Request started for: ${expertName}`);

    // 1. Check cache first (fastest path)
    const cached = this.getCachedPrediction(expertName);
    if (cached) {
      const elapsedTime = Date.now() - startTime;
      console.log(`[ExpertPrediction] Cache hit for ${expertName} in ${elapsedTime}ms`);
      return cached;
    }

    // 2. Check inflight deduplication
    const existingRequest = inflightRequests.get(expertName);
    if (existingRequest) {
      console.log(`[ExpertPrediction] Joining inflight request for ${expertName}`);
      try {
        const result = await existingRequest;
        const elapsedTime = Date.now() - startTime;
        console.log(`[ExpertPrediction] Inflight request completed for ${expertName} in ${elapsedTime}ms`);
        return result;
      } catch (error) {
        // If inflight request failed, continue with new request
        console.log(`[ExpertPrediction] Inflight request failed for ${expertName}, trying new request`);
      }
    }

    // 3. Check circuit breaker (fast-fail on known failures)
    if (this.shouldBreakCircuit(expertName)) {
      const fallbackResult = this.getFallbackPrediction(expertName);
      this.cachePrediction(expertName, fallbackResult);
      const elapsedTime = Date.now() - startTime;
      console.log(`[ExpertPrediction] Circuit breaker fallback for ${expertName} in ${elapsedTime}ms`);
      return fallbackResult;
    }

    // 4. Create new API request with hard deadline enforcement
    const requestPromise = this.makeApiRequestWithDeadline(expertName, startTime);
    inflightRequests.set(expertName, requestPromise);

    try {
      const result = await requestPromise;
      
      // Success: cache result and clear inflight
      this.cachePrediction(expertName, result);
      inflightRequests.delete(expertName);
      
      const elapsedTime = Date.now() - startTime;
      console.log(`[ExpertPrediction] API success for ${expertName} in ${elapsedTime}ms`);
      return result;
      
    } catch (error) {
      // Failure: record in circuit breaker, clear inflight, return fallback
      this.recordCircuitBreakerFailure(expertName, error);
      inflightRequests.delete(expertName);
      
      const fallbackResult = this.getFallbackPrediction(expertName);
      this.cachePrediction(expertName, fallbackResult);
      
      const elapsedTime = Date.now() - startTime;
      console.log(`[ExpertPrediction] API error for ${expertName} after ${elapsedTime}ms, using fallback`);
      return fallbackResult;
    }
  }

  private async makeApiRequestWithDeadline(expertName: string, requestStartTime: number): Promise<ExpertPrediction> {
    const remainingTime = HARD_DEADLINE - (Date.now() - requestStartTime);
    if (remainingTime <= 100) { // Less than 100ms remaining
      throw new Error('Hard deadline exceeded before API call');
    }

    // Create AbortController for hard deadline enforcement
    const controller = new AbortController();
    const timeoutId = setTimeout(() => {
      controller.abort();
    }, Math.min(remainingTime - 50, 1800)); // Leave 50ms buffer, max 1800ms

    try {
      const prompt = `å°‚é–€å®¶å: ${expertName}

ä»¥ä¸‹ã®JSONå½¢å¼ã§ç°¡æ½”ã«å›ç­”:
{
  "role": "ç°¡æ½”ãªå½¹å‰²ï¼ˆ1è¡Œï¼‰",
  "specialization": "ä¸»è¦å°‚é–€åˆ†é‡",
  "expertiseLevel": "specialist/expert/senior ã®ã„ãšã‚Œã‹",
  "subSpecializations": ["é ˜åŸŸ1", "é ˜åŸŸ2", "é ˜åŸŸ3"],
  "informationSources": ["æƒ…å ±æº1", "æƒ…å ±æº2"],
  "researchFocus": "ç ”ç©¶ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ï¼ˆç°¡æ½”ã«ï¼‰"
}

è¦ç‚¹ã‚’çµã‚Šå®Ÿç”¨çš„ãªå†…å®¹ã§æ—¥æœ¬èªå›ç­”ã€‚`;

      console.log(`[ExpertPrediction] Making API call for ${expertName} with ${remainingTime}ms remaining`);
      
      const response = await fastOpenai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: prompt }],
        response_format: { type: "json_object" },
        max_tokens: 150,
        temperature: 0.7,
      }, {
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      const responseContent = response.choices[0].message.content || "{}";
      const result = JSON.parse(responseContent);
      
      // Validate and set defaults if needed
      return {
        role: result.role || "",
        specialization: result.specialization || "",
        expertiseLevel: ["specialist", "expert", "senior"].includes(result.expertiseLevel) 
          ? result.expertiseLevel 
          : "expert",
        subSpecializations: Array.isArray(result.subSpecializations) 
          ? result.subSpecializations 
          : [],
        informationSources: Array.isArray(result.informationSources) 
          ? result.informationSources 
          : [],
        researchFocus: result.researchFocus || "",
      };
    } catch (error) {
      clearTimeout(timeoutId);
      
      // Check if it's an abort error (our timeout) or API error
      if (controller.signal.aborted) {
        throw new Error('Request aborted due to hard deadline');
      }
      
      throw error;
    }
  }

  async analyzeWithExpert(
    expertName: string, 
    expertRole: string, 
    theme: string, 
    currentStrategy: string, 
    targetYear: number,
    analysisId?: string
  ): Promise<ExpertAnalysis> {
    try {
      const prompt = `ã‚ãªãŸã¯ã€Œ${expertName}ã€ã¨ã—ã¦ã€ä»¥ä¸‹ã®åˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

å°‚é–€åˆ†é‡: ${expertRole}

åˆ†æå¯¾è±¡:
- æœªæ¥ãƒ†ãƒ¼ãƒ: ${theme}
- ç¾åœ¨ã®çµŒå–¶æˆ¦ç•¥: ${currentStrategy}
- äºˆæ¸¬å¹´: ${targetYear}å¹´

${expertName}ã®è¦–ç‚¹ã‹ã‚‰ã€${targetYear}å¹´ã«ãŠã‘ã‚‹ä¸Šè¨˜ãƒ†ãƒ¼ãƒã®å½±éŸ¿ã¨ã€ç¾åœ¨ã®çµŒå–¶æˆ¦ç•¥ã«å¯¾ã™ã‚‹å°‚é–€çš„ãªåŠ©è¨€ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
å…·ä½“çš„ãªèª²é¡Œã€æ©Ÿä¼šã€æ¨å¥¨äº‹é …ã‚’å«ã‚ã¦åˆ†æã—ã¦ãã ã•ã„ã€‚

JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„:
{
  "analysis": "è©³ç´°ãªåˆ†æå†…å®¹ï¼ˆ500æ–‡å­—ç¨‹åº¦ï¼‰",
  "recommendations": ["æ¨å¥¨äº‹é …1", "æ¨å¥¨äº‹é …2", "æ¨å¥¨äº‹é …3"]
}`;

      if (analysisId) {
        logApiRequest(analysisId, 1, `å°‚é–€å®¶åˆ†æ: ${expertName}`, prompt);
      }
      
      const response = await openai.chat.completions.create({
        model: "gpt-5",
        messages: [{ role: "user", content: prompt }],
        response_format: { type: "json_object" },
      });

      const responseContent = response.choices[0].message.content || "{}";
      if (analysisId) {
        logApiResponse(analysisId, 1, `å°‚é–€å®¶åˆ†æ: ${expertName}`, true, responseContent.length);
      }

      const result = JSON.parse(responseContent);
      
      return {
        expert: expertName,
        content: result.analysis || "åˆ†æçµæœã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚",
        recommendations: result.recommendations || [],
      };
    } catch (error) {
      console.error("Expert analysis error:", error);
      if (analysisId) {
        logApiResponse(analysisId, 1, `å°‚é–€å®¶åˆ†æ: ${expertName}`, false, 0, error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼');
      }
      return {
        expert: expertName,
        content: `${expertName}ã«ã‚ˆã‚‹åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`,
        recommendations: [],
      };
    }
  }

  async generateScenario(
    theme: string,
    currentStrategy: string,
    targetYear: number,
    expertAnalyses: ExpertAnalysis[],
    analysisId?: string
  ): Promise<string> {
    try {
      const expertSummary = expertAnalyses.map(analysis => 
        `${analysis.expert}: ${analysis.content}`
      ).join('\n\n');

      const prompt = `ä»¥ä¸‹ã®å°‚é–€å®¶åˆ†æã‚’åŸºã«ã€${targetYear}å¹´ã«ãŠã‘ã‚‹å…·ä½“çš„ãªã‚·ãƒŠãƒªã‚ªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

æœªæ¥ãƒ†ãƒ¼ãƒ: ${theme}
ç¾åœ¨ã®çµŒå–¶æˆ¦ç•¥: ${currentStrategy}
äºˆæ¸¬å¹´: ${targetYear}å¹´

å°‚é–€å®¶åˆ†æ:
${expertSummary}

ä¸Šè¨˜ã®åˆ†æã‚’çµ±åˆã—ã€${targetYear}å¹´ã«èµ·ã“ã‚Šã†ã‚‹å…·ä½“çš„ãªã‚·ãƒŠãƒªã‚ªã‚’è©³ç´°ã«æå†™ã—ã¦ãã ã•ã„ã€‚
ã‚·ãƒŠãƒªã‚ªã«ã¯ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„:
1. ç¤¾ä¼šãƒ»æŠ€è¡“ãƒ»çµŒæ¸ˆç’°å¢ƒã®å¤‰åŒ–
2. ç¾åœ¨ã®æˆ¦ç•¥ã¸ã®å½±éŸ¿
3. ä¼æ¥­ãŒç›´é¢ã™ã‚‹èª²é¡Œã¨æ©Ÿä¼š
4. æ¨å¥¨ã•ã‚Œã‚‹å¯¾å¿œç­–

JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„:
{
  "scenario": "è©³ç´°ãªã‚·ãƒŠãƒªã‚ªï¼ˆ800æ–‡å­—ç¨‹åº¦ï¼‰"
}`;

      if (analysisId) {
        logApiRequest(analysisId, 2, "ã‚·ãƒŠãƒªã‚ªç”Ÿæˆ", prompt);
      }
      
      const response = await openai.chat.completions.create({
        model: "gpt-5",
        messages: [{ role: "user", content: prompt }],
        response_format: { type: "json_object" },
      });

      const responseContent = response.choices[0].message.content || "{}";
      if (analysisId) {
        logApiResponse(analysisId, 2, "ã‚·ãƒŠãƒªã‚ªç”Ÿæˆ", true, responseContent.length);
      }

      const result = JSON.parse(responseContent);
      return result.scenario || "ã‚·ãƒŠãƒªã‚ªã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚";
    } catch (error) {
      console.error("Scenario generation error:", error);
      if (analysisId) {
        logApiResponse(analysisId, 2, "ã‚·ãƒŠãƒªã‚ªç”Ÿæˆ", false, 0, error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼');
      }
      return `ã‚·ãƒŠãƒªã‚ªç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`;
    }
  }

  async generateLongTermPerspective(
    theme: string,
    currentStrategy: string,
    longTermYear: number,
    nearTermYear: number,
    analysisId?: string
  ): Promise<string> {
    try {
      const prompt = `${longTermYear}å¹´ã®è¦–ç‚¹ã‹ã‚‰${nearTermYear}å¹´ã®æˆ¦ç•¥ã‚’è©•ä¾¡ã—ã€è¶…é•·æœŸçš„ãªè¦³ç‚¹ã§ã®æè¨€ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

æœªæ¥ãƒ†ãƒ¼ãƒ: ${theme}
ç¾åœ¨ã®çµŒå–¶æˆ¦ç•¥: ${currentStrategy}
é•·æœŸè¦–ç‚¹å¹´: ${longTermYear}å¹´
è©•ä¾¡å¯¾è±¡å¹´: ${nearTermYear}å¹´

${longTermYear}å¹´ã‹ã‚‰æŒ¯ã‚Šè¿”ã£ã¦ã€${nearTermYear}å¹´æ™‚ç‚¹ã§é‡è¦ã«ãªã‚‹è¦ç´ ã¨ã€ç¾åœ¨å–ã‚‹ã¹ãæˆ¦ç•¥çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„:
{
  "perspective": "é•·æœŸçš„ãªè¦–ç‚¹ã‹ã‚‰ã®åˆ†æï¼ˆ600æ–‡å­—ç¨‹åº¦ï¼‰",
  "key_factors": ["é‡è¦è¦ç´ 1", "é‡è¦è¦ç´ 2", "é‡è¦è¦ç´ 3"],
  "strategic_actions": ["æˆ¦ç•¥çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1", "æˆ¦ç•¥çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2", "æˆ¦ç•¥çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³3"]
}`;

      if (analysisId) {
        logApiRequest(analysisId, 3, "é•·æœŸè¦–ç‚¹åˆ†æ", prompt);
      }
      
      const response = await openai.chat.completions.create({
        model: "gpt-5",
        messages: [{ role: "user", content: prompt }],
        response_format: { type: "json_object" },
      });

      const responseContent = response.choices[0].message.content || "{}";
      if (analysisId) {
        logApiResponse(analysisId, 3, "é•·æœŸè¦–ç‚¹åˆ†æ", true, responseContent.length);
      }

      const result = JSON.parse(responseContent);
      return result.perspective || "é•·æœŸçš„è¦–ç‚¹ã®åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚";
    } catch (error) {
      console.error("Long-term perspective error:", error);
      if (analysisId) {
        logApiResponse(analysisId, 3, "é•·æœŸè¦–ç‚¹åˆ†æ", false, 0, error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼');
      }
      return `é•·æœŸçš„è¦–ç‚¹ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`;
    }
  }

  async evaluateStrategicAlignment(
    theme: string,
    currentStrategy: string,
    targetYear: number,
    scenarios: string[],
    analysisId?: string
  ): Promise<string> {
    try {
      const scenarioSummary = scenarios.join('\n\n');

      const prompt = `ä»¥ä¸‹ã®ã‚·ãƒŠãƒªã‚ªåˆ†æã«åŸºã¥ã„ã¦ã€ç¾åœ¨ã®çµŒå–¶æˆ¦ç•¥ã®æ•´åˆæ€§ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

æœªæ¥ãƒ†ãƒ¼ãƒ: ${theme}
ç¾åœ¨ã®çµŒå–¶æˆ¦ç•¥: ${currentStrategy}
äºˆæ¸¬å¹´: ${targetYear}å¹´

ç”Ÿæˆã•ã‚ŒãŸã‚·ãƒŠãƒªã‚ª:
${scenarioSummary}

ç¾åœ¨ã®çµŒå–¶æˆ¦ç•¥ãŒã“ã‚Œã‚‰ã®ã‚·ãƒŠãƒªã‚ªã«ã©ã®ç¨‹åº¦é©åˆã—ã¦ã„ã‚‹ã‹ã€ã¾ãŸæˆ¦ç•¥ä¿®æ­£ã®å¿…è¦æ€§ã«ã¤ã„ã¦è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„:
{
  "alignment_score": "1-10ã®ã‚¹ã‚³ã‚¢",
  "strengths": ["å¼·ã¿ãƒ»æ©Ÿä¼š1", "å¼·ã¿ãƒ»æ©Ÿä¼š2", "å¼·ã¿ãƒ»æ©Ÿä¼š3"],
  "weaknesses": ["èª²é¡Œãƒ»ãƒªã‚¹ã‚¯1", "èª²é¡Œãƒ»ãƒªã‚¹ã‚¯2", "èª²é¡Œãƒ»ãƒªã‚¹ã‚¯3"],
  "recommendations": ["æ¨å¥¨äº‹é …1", "æ¨å¥¨äº‹é …2", "æ¨å¥¨äº‹é …3"]
}`;

      if (analysisId) {
        logApiRequest(analysisId, 4, "æˆ¦ç•¥æ•´åˆæ€§è©•ä¾¡", prompt);
      }
      
      const response = await openai.chat.completions.create({
        model: "gpt-5",
        messages: [{ role: "user", content: prompt }],
        response_format: { type: "json_object" },
      });

      const responseContent = response.choices[0].message.content || "{}";
      if (analysisId) {
        logApiResponse(analysisId, 4, "æˆ¦ç•¥æ•´åˆæ€§è©•ä¾¡", true, responseContent.length);
      }

      const result = JSON.parse(responseContent);
      return JSON.stringify(result);
    } catch (error) {
      console.error("Strategic alignment evaluation error:", error);
      if (analysisId) {
        logApiResponse(analysisId, 4, "æˆ¦ç•¥æ•´åˆæ€§è©•ä¾¡", false, 0, error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼');
      }
      return JSON.stringify({
        alignment_score: "è©•ä¾¡ä¸å¯",
        strengths: ["è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"],
        weaknesses: [error instanceof Error ? error.message : "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼"],
        recommendations: ["å¾Œã§å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„"]
      });
    }
  }

  async generateFinalSimulation(
    theme: string,
    currentStrategy: string,
    targetYear: number,
    allAnalyses: string[],
    analysisId?: string
  ): Promise<string> {
    try {
      const analysisSummary = allAnalyses.join('\n\n');

      const prompt = `ã“ã‚Œã¾ã§ã®å…¨ã¦ã®åˆ†æã‚’çµ±åˆã—ã€æœ€çµ‚çš„ãªã‚·ãƒŠãƒªã‚ªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

æœªæ¥ãƒ†ãƒ¼ãƒ: ${theme}
ç¾åœ¨ã®çµŒå–¶æˆ¦ç•¥: ${currentStrategy}
äºˆæ¸¬å¹´: ${targetYear}å¹´

çµ±åˆåˆ†æ:
${analysisSummary}

ä¸Šè¨˜ã®å…¨åˆ†æã‚’çµ±åˆã—ã€æœ€ã‚‚å®Ÿç¾å¯èƒ½æ€§ã®é«˜ã„æœªæ¥ã‚·ãƒŠãƒªã‚ªã¨ã€ä¼æ¥­ãŒå–ã‚‹ã¹ãå…·ä½“çš„ãªæˆ¦ç•¥ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚

JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„:
{
  "final_scenario": "æœ€çµ‚çµ±åˆã‚·ãƒŠãƒªã‚ªï¼ˆ800æ–‡å­—ç¨‹åº¦ï¼‰",
  "strategic_priorities": ["å„ªå…ˆæˆ¦ç•¥1", "å„ªå…ˆæˆ¦ç•¥2", "å„ªå…ˆæˆ¦ç•¥3"],
  "success_factors": ["æˆåŠŸè¦å› 1", "æˆåŠŸè¦å› 2", "æˆåŠŸè¦å› 3"],
  "implementation_steps": ["å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—1", "å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—2", "å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—3"]
}`;

      if (analysisId) {
        logApiRequest(analysisId, 5, "æœ€çµ‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", prompt);
      }
      
      const response = await openai.chat.completions.create({
        model: "gpt-5",
        messages: [{ role: "user", content: prompt }],
        response_format: { type: "json_object" },
      });

      const responseContent = response.choices[0].message.content || "{}";
      if (analysisId) {
        logApiResponse(analysisId, 5, "æœ€çµ‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", true, responseContent.length);
      }

      const result = JSON.parse(responseContent);
      return result.final_scenario || "æœ€çµ‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚";
    } catch (error) {
      console.error("Final simulation error:", error);
      if (analysisId) {
        logApiResponse(analysisId, 5, "æœ€çµ‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", false, 0, error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼');
      }
      return `æœ€çµ‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`;
    }
  }

  generateMarkdownReport(
    theme: string,
    currentStrategy: string,
    targetYears: number[],
    phases: PhaseResult[]
  ): string {
    const date = new Date().toISOString().split('T')[0];
    
    let markdown = `# æœªæ¥äºˆæ¸¬AIã‚·ãƒŠãƒªã‚ªåˆ†æãƒ¬ãƒãƒ¼ãƒˆ

**ç”Ÿæˆæ—¥:** ${date}
**åˆ†æãƒ†ãƒ¼ãƒ:** ${theme}
**ç¾åœ¨ã®çµŒå–¶æˆ¦ç•¥:** ${currentStrategy}
**äºˆæ¸¬å¹´:** ${targetYears.join(', ')}

---

## ğŸ“‹ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯ã€AIå°‚é–€å®¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹æœªæ¥äºˆæ¸¬åˆ†æã®çµæœã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚
è¤‡æ•°ã®å°‚é–€å®¶ã®è¦–ç‚¹ã‚’çµ±åˆã—ã€${targetYears[0]}å¹´ã‚’ä¸­å¿ƒã¨ã—ãŸæœªæ¥ã‚·ãƒŠãƒªã‚ªã‚’åˆ†æã—ã¾ã—ãŸã€‚

---

`;

    phases.forEach((phase, index) => {
      markdown += `## Phase ${index + 1}: ${phase.title}\n\n`;
      markdown += `${phase.content}\n\n`;

      if (phase.analyses && phase.analyses.length > 0) {
        markdown += `### å°‚é–€å®¶åˆ†æ\n\n`;
        phase.analyses.forEach(analysis => {
          markdown += `#### ${analysis.expert}\n\n`;
          markdown += `${analysis.content}\n\n`;
          if (analysis.recommendations.length > 0) {
            markdown += `**æ¨å¥¨äº‹é …:**\n`;
            analysis.recommendations.forEach(rec => {
              markdown += `- ${rec}\n`;
            });
            markdown += `\n`;
          }
        });
      }

      if (phase.recommendations && phase.recommendations.length > 0) {
        markdown += `### ä¸»è¦æ¨å¥¨äº‹é …\n\n`;
        phase.recommendations.forEach(rec => {
          markdown += `- ${rec}\n`;
        });
        markdown += `\n`;
      }

      markdown += `---\n\n`;
    });

    markdown += `## ğŸ¯ ç·åˆæè¨€

ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã«åŸºã¥ãã€ä»¥ä¸‹ã®æˆ¦ç•¥çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¨å¥¨ã—ã¾ã™ï¼š

1. **çŸ­æœŸçš„æ–½ç­–ï¼ˆ1-2å¹´ï¼‰:** ç¾åœ¨ã®æˆ¦ç•¥ã®å¼·åŒ–ã¨åŸºç›¤æ•´å‚™
2. **ä¸­æœŸçš„æ–½ç­–ï¼ˆ3-5å¹´ï¼‰:** æ–°æŠ€è¡“ãƒ»æ–°å¸‚å ´ã¸ã®é©å¿œæº–å‚™
3. **é•·æœŸçš„æ–½ç­–ï¼ˆ5å¹´ä»¥ä¸Šï¼‰:** æŒç¶šå¯èƒ½ãªç«¶äº‰å„ªä½ã®æ§‹ç¯‰

---

*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ AI å°‚é–€å®¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚*
`;

    return markdown;
  }

  generateMarkdownReportMultiYear(
    theme: string,
    currentStrategy: string,
    targetYears: number[],
    yearResults: YearResult[]
  ): string {
    const date = new Date().toISOString().split('T')[0];
    
    let markdown = `# æœªæ¥äºˆæ¸¬AIã‚·ãƒŠãƒªã‚ªåˆ†æãƒ¬ãƒãƒ¼ãƒˆï¼ˆè¤‡æ•°å¹´äºˆæ¸¬ï¼‰

**ç”Ÿæˆæ—¥:** ${date}
**åˆ†æãƒ†ãƒ¼ãƒ:** ${theme}
**ç¾åœ¨ã®çµŒå–¶æˆ¦ç•¥:** ${currentStrategy}
**äºˆæ¸¬å¹´:** ${targetYears.join(', ')}

---

## ğŸ“‹ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯ã€AIå°‚é–€å®¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹è¤‡æ•°å¹´ã«ã‚ãŸã‚‹æœªæ¥äºˆæ¸¬åˆ†æã®çµæœã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚
${targetYears.map(year => `${year}å¹´`).join('ã€')}ã«ãŠã‘ã‚‹æœªæ¥ã‚·ãƒŠãƒªã‚ªã‚’ã€æ®µéšçš„ã«åˆ†æã—ã¦ã„ã¾ã™ã€‚

---

## ğŸ“Š å¹´åˆ¥åˆ†æçµæœã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

`;

    yearResults.forEach(yearResult => {
      markdown += `- [${yearResult.year}å¹´ã®åˆ†æ](#${yearResult.year}å¹´ã®æœªæ¥äºˆæ¸¬ã‚·ãƒŠãƒªã‚ª)
`;
    });

    markdown += `
---

`;

    // Generate content for each year
    yearResults.forEach((yearResult, yearIndex) => {
      markdown += `## ${yearResult.year}å¹´ã®æœªæ¥äºˆæ¸¬ã‚·ãƒŠãƒªã‚ª

`;
      
      yearResult.phases.forEach((phase, phaseIndex) => {
        markdown += `### Phase ${phaseIndex + 1}: ${phase.title}

`;
        markdown += `${phase.content}

`;

        if (phase.analyses && phase.analyses.length > 0) {
          markdown += `#### å°‚é–€å®¶åˆ†æ

`;
          phase.analyses.forEach(analysis => {
            markdown += `##### ${analysis.expert}

`;
            markdown += `${analysis.content}

`;
            if (analysis.recommendations.length > 0) {
              markdown += `**æ¨å¥¨äº‹é …:**
`;
              analysis.recommendations.forEach(rec => {
                markdown += `- ${rec}
`;
              });
              markdown += `
`;
            }
          });
        }

        if (phase.recommendations && phase.recommendations.length > 0) {
          markdown += `#### ä¸»è¦æ¨å¥¨äº‹é …

`;
          phase.recommendations.forEach(rec => {
            markdown += `- ${rec}
`;
          });
          markdown += `
`;
        }
      });

      if (yearIndex < yearResults.length - 1) {
        markdown += `---

`;
      }
    });

    markdown += `---

## ğŸ¯ è¤‡æ•°å¹´ç·åˆæè¨€

ã“ã®è¤‡æ•°å¹´åˆ†æã«åŸºã¥ãã€ä»¥ä¸‹ã®æ®µéšçš„æˆ¦ç•¥ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¨å¥¨ã—ã¾ã™ï¼š

`;

    targetYears.forEach((year, index) => {
      const timeframe = index === 0 ? 'çŸ­æœŸçš„æ–½ç­–' : index === 1 ? 'ä¸­æœŸçš„æ–½ç­–' : 'é•·æœŸçš„æ–½ç­–';
      markdown += `${index + 1}. **${timeframe}ï¼ˆ${year}å¹´ç›®æ¨™ï¼‰:** æ®µéšçš„ãªæˆ¦ç•¥å±•é–‹ã¨é©å¿œ
`;
    });

    markdown += `
---

*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ AI å°‚é–€å®¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚*
`;

    return markdown;
  }
}

export const openAIService = new OpenAIService();
